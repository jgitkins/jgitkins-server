{
  "master": {
    "tasks": [
      {
        "id": "1",
        "title": "Feature Runner Management API",
        "description": "Create the core pipeline/job aggregates, DTOs, and storage ports that will back CI orchestration.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "You asked: \"Please Translate Implementation Detail to korean.\" A more natural phrasing is: \"Please translate the implementation details into Korean.\" 이후 구현 지침은 한국어로 정리했습니다.\n`src/main/java/io/jgitkins/server/domain/model/Job.java`에서 사용하는 Aggregate/Value Object 패턴을 벤치마킹해 `application/domain` 패키지에 `PipelineJob`, `PipelineStage`, `JobStatus`, `RunnerAssignment` 레코드를 추가하고, 각 객체에 저장소 경로·taskCd·commitSha·requestedBy·Jenkinsfile digest·큐 진입/할당 시각 등 메타데이터를 포함한다. `application/dto`에는 `PipelineJobCommand` 계열 DTO를 두고 `presentation/mapper` 아래 기존 MapStruct 예제(`CreateRepositoryMapper`)처럼 `@Mapper(componentModel = \"spring\")` 인터페이스를 만들어 REST 요청 ↔ 도메인 변환을 담당하게 한다. `application/port/out`에는 `PipelineJobPersistencePort`를 선언하고, `infrastructure/persistence/adapter`에 ConcurrentHashMap 기반 인메모리 구현을 두며 이후 DB 어댑터로 교체할 수 있도록 Spring 구성(`src/main/java/io/jgitkins/server/config` 참고)에서 빈으로 주입한다. 저장/조회/락 동작에 대한 의사코드는 `PipelineJob job = PipelineJob.create(taskCd, repoName, commitSha, definition); pipelineJobRepository.save(job);` 형태로 문서화하고, Runner 관련 Task 4에서 사용할 수 있도록 `RunnerAssignment`가 Runner 이미지/플러그인 매니페스트 식별자를 참조할 수 있게 설계한다.",
        "testStrategy": "도메인 팩토리 및 상태 전이(pending→queued→running→succeeded) 로직은 `src/test/java/.../domain`에 단위 테스트를 추가하고, 인메모리 `PipelineJobPersistencePort` 어댑터는 Spring Boot 슬라이스 테스트로 save/find/lock 시나리오를 검증한다.",
        "subtasks": [
          {
            "id": 1,
            "title": "Runner Registration API",
            "description": "Wokring Create an API to Register Runner such as GitLab CI",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined",
            "updatedAt": "2025-12-08T07:31:21.514Z"
          },
          {
            "id": 2,
            "title": "Runner Integration API",
            "description": "Feature Integration API to Integration Runner's Instance",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Runner Loading API",
            "description": "Runner 조회 API",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Runner Delete API",
            "description": "Runner 삭제 API",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1,
            "parentId": "undefined"
          }
        ],
        "updatedAt": "2025-12-08T07:31:21.514Z"
      },
      {
        "id": "2",
        "title": "Feature Integrate MQ",
        "description": "Introduce the Feature MQ message-bus so the CI coordinator can asynchronously push pipeline job definitions and runner heartbeat signals between the Spring Boot orchestrator and external JGitkins Runners, ensuring jobs created from parsed Jenkinsfiles are queued and acknowledged reliably.",
        "status": "in-progress",
        "dependencies": [],
        "priority": "medium",
        "details": "요청 문구 개선: “Please translate the implementation details into Korean.” 이하 구현 지침은 한국어로 정리했습니다.\n`src/main/java/io/jgitkins/server/application/port/out/` 패키지에 `RepositoryContentPort`(참고: RepositoryService가 사용)와 나란히 `JobQueuePort`, `RunnerHeartbeatPort`를 추가해 애플리케이션 계층이 저장소·메시징 구현에서 분리되도록 한다. 각 포트는 Jenkinsfile 파싱 이후 생성되는 잡 메타데이터(`job_id`, `repository_id`, `commit_hash`, `runner_id`, 타임스탬프)를 직렬화·enqueue/dequeue하거나 러너 하트비트를 upsert/조회하는 메서드를 정의한다. 인프라 계층에는 `src/main/java/io/jgitkins/server/infrastructure/adapter/mq/` 이하에 인메모리 구현(예: `InMemoryJobQueueAdapter`, `InMemoryRunnerHeartbeatAdapter`)을 두고, 향후 실제 MQ 프로바이더로 교체할 수 있도록 스프링 빈 구성을 `infrastructure/config/mq/MessagingConfig`에서 관리한다. 파이프라인 잡 생성 서비스(`src/main/java/io/jgitkins/server/application/port/service/` 내 예정)에는 새 포트를 주입하여 Jenkinsfile 파싱 시 직렬화 payload를 큐에 push하고 실패 시 도메인 예외를 던지며, 하트비트 어댑터를 통해 러너 생존 신호를 읽고 필요 시 갱신한다. 큐 작업 중 발생한 예외는 도메인 계층으로 전파하여 디스패처가 enqueue 실패를 감지하도록 한다.",
        "testStrategy": "Add unit tests around the new `JobQueuePort`-backed service to ensure payloads derived from job metadata (repo, commit, runner assignment) are serialized consistently before enqueue. Provide integration-style tests that spin up the in-memory MQ adapter in Spring and verify enqueue/dequeue semantics plus error propagation when the queue is unavailable.",
        "subtasks": [
          {
            "id": 1,
            "title": "Define MQ application ports and payload DTOs",
            "description": "Add queue-specific contracts in the application layer so services can enqueue jobs and track runner heartbeats without binding to infrastructure.",
            "dependencies": [],
            "details": "`src/main/java/io/jgitkins/server/application/port/out/`에 `JobQueuePort`, `RunnerHeartbeatPort` 인터페이스를 추가하여 enqueue/dequeue, ack, 하트비트 조회·저장을 추상화하고, DTO(`application/dto/JobQueuePayload`, `RunnerHeartbeatSnapshot`)에는 `job_id`, `repository_id`, `commit_hash`, `runner_id`, 타임스탬프 필드를 포함한 불변 객체를 정의한다. 큐 작업 실패를 표준화하기 위해 `application/exception/JobQueueException`(새로운 패키지 위치 허용)을 만들어 서비스 계층이 명확한 메시지와 함께 예외를 전달할 수 있게 한다.",
            "status": "pending",
            "testStrategy": "Add compile-time focused unit tests (or contract tests using mocks) to ensure DTO builders and exception wiring behave as expected.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implement in-memory MQ adapters",
            "description": "Provide infrastructure adapters that satisfy the new queue ports using in-memory data structures to unblock development while keeping the design swappable for a real MQ provider later.",
            "dependencies": [
              1
            ],
            "details": "`src/main/java/io/jgitkins/server/infrastructure/adapter/mq/`에 `InMemoryJobQueueAdapter`(예: `BlockingQueue<JobQueuePayload>` 기반)와 `InMemoryRunnerHeartbeatAdapter`(예: `ConcurrentHashMap<String, RunnerHeartbeatSnapshot>`)를 구현해 각각 `JobQueuePort`, `RunnerHeartbeatPort`를 충족시키고, Spring `@Component` 혹은 구성 클래스로 빈 등록 가능한 형태로 작성한다. 큐 오퍼레이션 실패 시 `JobQueueException`을 던지며, 로그에 직렬화된 payload/runner id를 포함해 추적하기 쉽게 만든다.",
            "status": "pending",
            "testStrategy": "Write focused unit tests targeting the adapters (e.g., verifying enqueue/dequeue order, heartbeat freshness) using plain JUnit without Spring context.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Wire MQ adapters through Spring configuration",
            "description": "Expose the in-memory queue adapters as beans and prepare configuration hooks so future MQ providers can replace them cleanly.",
            "dependencies": [
              2
            ],
            "details": "`src/main/java/io/jgitkins/server/infrastructure/config/mq/MessagingConfig.java`(새 디렉터리)에서 `@Configuration` 클래스를 정의하고 `@Bean` 메서드로 인메모리 어댑터를 등록하며, `@ConditionalOnMissingBean(JobQueuePort.class)` 등 조건을 붙여 실제 MQ 구현이 존재할 경우 자동으로 대체되도록 한다. 러너 하트비트 만료 처리나 재시도 스케줄러가 필요하면 같은 구성 클래스 안에서 `TaskScheduler` 또는 `Executor` 빈을 정의해 어댑터에 주입한다.",
            "status": "pending",
            "testStrategy": "Add a simple Spring context test verifying the configuration loads and that `JobQueuePort` and `RunnerHeartbeatPort` beans resolve without conflicts.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Extend job creation flow to emit MQ events",
            "description": "Hook the new ports into the service that turns parsed Jenkinsfiles into runnable jobs so every job is serialized and enqueued reliably.",
            "dependencies": [
              1,
              3
            ],
            "details": "`src/main/java/io/jgitkins/server/application/port/service/` 경로에 `PipelineJobService`(또는 기존 서비스 확장)를 두고, Jenkinsfile 파싱으로 생성된 잡 엔터티를 `JobQueuePayload`로 변환하여 `JobQueuePort.enqueue`를 호출한다. 직렬화 시 `data/ERD.md`에 맞춘 필드 네이밍을 유지하며, enqueue 실패는 `JobQueueException`으로 감싸 상위 호출자가 재시도/롤백을 결정할 수 있게 한다. 러너 배정 전 하트비트 확인이 필요하면 `RunnerHeartbeatPort`를 주입해 특정 러너가 최신 신호를 보냈는지 검사하고, 필요 시 하트비트를 갱신하는 헬퍼 메서드를 추가한다.",
            "status": "pending",
            "testStrategy": "Use a service-level unit test with mocked `JobQueuePort` to ensure payload serialization matches ERD fields and exceptions propagate when enqueueing fails.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Add end-to-end tests covering queue publishing and heartbeat semantics",
            "description": "Prove the MQ integration works by exercising the in-memory adapters inside a Spring test slice that simulates job creation and runner heartbeats.",
            "dependencies": [
              1,
              2,
              4
            ],
            "details": "`src/test/java/io/jgitkins/server/mq/JobQueueIntegrationTest` 등 패키지에서 스프링 테스트 슬라이스를 띄우고 `MessagingConfig`를 불러온 뒤, 페이크 파이프라인 잡을 persist/생성하고 서비스가 `JobQueuePort`를 통해 enqueue 했는지, 인메모리 큐에 직렬화 payload가 저장됐는지, `RunnerHeartbeatPort`가 러너 하트비트 타임스탬프를 최신 상태로 유지하는지 검증한다. 큐 예외를 강제로 발생시켜 도메인 예외가 상위로 전파되는 네거티브 시나리오도 포함한다.",
            "status": "pending",
            "testStrategy": "Spring Boot integration-style tests using the in-memory adapters to validate enqueue/dequeue + heartbeat freshness, alongside assertions on emitted payload fields.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Job Creation UseCase",
            "description": "Working Creation Job UseCase And Integration",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 2,
            "updatedAt": "2025-12-04T08:37:59.733Z",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Job Message Publish",
            "description": "1. Scheduling 작업 진행\n2. Dispatch Job to Runnable Runner",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 2,
            "parentId": "undefined",
            "updatedAt": "2025-12-10T11:05:16.998Z"
          }
        ],
        "updatedAt": "2025-12-10T11:05:16.998Z"
      },
      {
        "id": "3",
        "title": "Feature Batch Job Publisher",
        "description": "Create a scheduled dispatcher that scans stored pipeline jobs and enqueues them only when at least one runnable runner is currently reporting heartbeats.",
        "details": "1. Follow the service layout under `src/main/java/io/jgitkins/server/application/port/service/` (see `RepositoryService` as a reference) to add a `JobDispatchService` that consumes `PipelineJobPersistencePort`, `JobQueuePort`, and `RunnerHeartbeatPort` (from Tasks 1 & 2). The service should expose `publishPendingJobs()` that: a) loads pending `PipelineJob`s flagged as runnable, b) checks runner availability via heartbeat data (only runners with recent timestamps and matching labels/architectures should qualify), c) transitions the job status to `QUEUED` and persists it before enqueueing via `JobQueuePort`, and d) skips jobs when no runner fits.\n2. Implement a Spring `@Component` scheduler (e.g., `PipelineJobPublisherBatch` under `src/main/java/io/jgitkins/server/infrastructure/batch/`) using `@Scheduled(fixedDelay = …)` and enable scheduling in `JGitkinsServerApplication` if not already. The batch should call `JobDispatchService.publishPendingJobs()` and log outcomes with structured log messages (job id, runner id) using SLF4J, mirroring logging already present in adapters like `JGitRepositoryAdapter`.\n3. Add configuration knobs in `application.yml` (new `jgitkins.dispatcher.*` section) for delay interval, heartbeat freshness threshold, and per-runner concurrency guard. Bind them via a `@ConfigurationProperties` class under `infrastructure/config` similar to existing configs (e.g., `DataSourceConfig`). Inject these properties into the batch component.\n4. Extend the domain from Task 1 by documenting the new `QUEUED` transition and runner-selection constraints inside the `PipelineJob` aggregate (update its JavaDoc or KDoc comments once implemented) so later tasks understand invariants. Ensure the dispatch logic throws `ResourceLockedException` when concurrent updates race, matching existing exception types in `application/common/exception`.\n5. Prepare the infrastructure adapter for recording runner occupancy: add a lightweight `RunnerAssignmentTracker` (in-memory Map for now) under `infrastructure/adapter/mq/` that mirrors how other adapters (e.g., `JGitBranchAdapter`) encapsulate external resources, so future MQ-backed implementations can reuse the selection logic.",
        "testStrategy": "- Add unit tests in `src/test/java/.../application/port/service/JobDispatchServiceTest` using mocks for `PipelineJobPersistencePort`, `JobQueuePort`, and `RunnerHeartbeatPort` to cover: (a) publishing succeeds when a runner is available, (b) no enqueue occurs when no runner heartbeat meets freshness criteria, and (c) concurrency guard prevents double enqueue. Use Spring’s `@ExtendWith(SpringExtension.class)` and Mockito as in existing tests.\n- Create a Spring Boot slice/integration test (e.g., `PipelineJobPublisherBatchIT`) that wires the real in-memory adapters, runs the `PipelineJobPublisherBatch` via `@SpringBootTest` with `@ActiveProfiles(\"test\")`, and verifies that jobs inserted through the persistence port are moved to the in-memory queue only when a heartbeat entry exists.\n- Include a configuration binding test asserting that `jgitkins.dispatcher` properties map correctly by loading the context with a custom `@TestPropertySource`.",
        "status": "pending",
        "dependencies": [
          "1",
          "2"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": "4",
        "title": "Feature Runner Image & Plugin Catalog",
        "description": "Introduce server-side management for Runner base images and plugin manifests so runners can fetch a curated `plugin.yaml` describing the plugins they should install.",
        "details": "1. Model runner assets beside existing domain records (see `src/main/java/io/jgitkins/server/application/domain`) by adding `RunnerImage`, `RunnerPluginDescriptor`, and `RunnerManifest` aggregates that capture image digest, supported architectures, plugin metadata, and last-updated hashes so `RunnerAssignment` from Task 1 can reference a concrete manifest version when dispatching jobs.\n2. Define input DTOs/use cases (`RegisterRunnerImageCommand`, `UpdateRunnerManifestCommand`, etc.) under `application/port/in` patterned after `CreateRepositoryUseCase`, plus new outbound ports `RunnerCatalogPort` and `RunnerManifestPort` in `application/port/out` for storing image inventory and persisting runner-specific `plugin.yaml` content.\n3. Implement `RunnerManagementService` in `application/port/service` (follow `RepositoryService` structure) coordinating validation (unique image name, plugin compatibility with image architecture), diffing manifests, and exposing methods for runners to fetch resolved manifests or request plugin refresh tokens.\n4. Provide infrastructure adapters in `src/main/java/io/jgitkins/server/infrastructure/adapter/persistence` backed by an in-memory map plus filesystem snapshots under `data/runner-manifests/<runnerId>/plugin.yaml`; introduce a `PluginYamlMapper` component that uses Jackson YAML (`com.fasterxml.jackson.dataformat:jackson-dataformat-yaml`) added to `build.gradle` to convert manifest aggregates to canonical YAML before storing.\n5. Add REST endpoints in a new `RunnerManagementController` (`presentation/api`) with POST/GET routes for image registration, plugin manifest updates, manifest retrieval, and plugin checksum introspection; reuse the mapper style from `BranchCreateMapper` for translating DTOs, enforce optimistic locking via ETag headers so runners do not download unchanged manifests.\n6. Document the workflow in `README.md` Runner Management section describing how runners call the new endpoints to sync their images/plugins and how plugin manifests relate to Task 2's MQ heartbeat payloads once available.",
        "testStrategy": "- Domain/unit tests under `src/test/java/.../domain` verifying manifest merge logic, architecture validation, and YAML round-trip serialization (object -> YAML -> object matches expected fields).\n- Service-layer tests mocking `RunnerCatalogPort` and `RunnerManifestPort` to ensure registration rejects duplicate images, plugin updates create new manifest revisions, and checksum calculation matches stored YAML bytes.\n- Adapter integration tests using `@SpringBootTest` with temporary directories to assert the persistence adapter writes readable `plugin.yaml` files under `data/runner-manifests/<runnerId>` and reloads them on startup.\n- MVC tests (`@WebMvcTest(RunnerManagementController.class)`) confirming HTTP contracts, validation errors, and ETag handling for the new endpoints.",
        "status": "pending",
        "dependencies": [
          "1"
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": "5",
        "title": "Scheduled Job Publication Flow",
        "description": "Implement a scheduler-driven service that detects pending pipeline jobs, ensures a compatible runnable runner exists, updates job history, and enqueues the job for execution.",
        "details": "1. Add a Spring `@Scheduled` component (e.g., `JobSchedulePoller` under `src/main/java/io/jgitkins/server/application/scheduling/`) that invokes the existing `JobDispatchService.publishPendingJobs()` from Task 3 at configurable intervals (default 30s via `application.yml`).\n2. Within `JobDispatchService`, implement logic to query `PipelineJobPersistencePort` for pending jobs, ask `RunnerHeartbeatPort` for runners whose heartbeats fall within the freshness window and match required labels/arch, and pick the best runner via `RunnerAssignment` metadata.\n3. When a runner is selected, update the job’s domain aggregate: append a history entry (new `JobHistoryEvent`/value object) capturing transition `PENDING→QUEUED`, runner id, timestamp, and any queue reference.\n4. Persist the updated job via `PipelineJobPersistencePort` using optimistic locking to prevent duplicate dispatch, then call `JobQueuePort.enqueue()` with a DTO mirroring Task 2’s payload specification.\n5. Emit structured logs/metrics (Micrometer counter for dispatched jobs, gauge for backlog) to aid observability and ensure the scheduler is idempotent (skip processing when no runners qualify).",
        "testStrategy": "- Add `JobDispatchServiceTest` cases: (a) verifies pending job transitions to queued when a fresh runner is available—assert history entry and enqueue call; (b) ensures no enqueue when no runner passes freshness/label filters; (c) concurrency test mocking persistence lock failure to confirm retry/skip behavior.\n- Create `JobSchedulePollerTest` (Spring slice) to assert the scheduler delegates to `JobDispatchService` and honors configuration (use `@ExtendWith(SpringExtension.class)` plus `@Import(JobSchedulePoller.class)` with mocked service).\n- Optional integration test wiring in-memory implementations of ports to ensure full flow updates job records and publishes to queue.",
        "status": "pending",
        "dependencies": [
          "1",
          "2",
          "3"
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2025-12-10T11:05:17.001Z",
      "taskCount": 5,
      "completedCount": 1,
      "tags": [
        "master"
      ]
    }
  }
}